{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from debug_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader, test_loader = load_mnist(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = get_batch(train_loader)\n",
    "images, labels = images.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "leaf_model = CNN().to(device)\n",
    "model_1 = CNN().to(device)\n",
    "\n",
    "learning_rate = torch.tensor(1e-3, dtype=torch.float32, requires_grad=True, device=device)\n",
    "\n",
    "print(learning_rate.grad)\n",
    "\n",
    "outputs = leaf_model(images)\n",
    "leaf_model.zero_grad()\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "\n",
    "# параметры которе запомнили вычислительный граф\n",
    "new_params = {name: param - learning_rate * param.grad for name, param in leaf_model.named_parameters()}\n",
    "\n",
    "# Переносим параметры с одной модели на другую, сохраняя отслеживание градиентов\n",
    "for (name, param), (_, new_param) in zip(model_1.named_parameters(), new_params.items()):\n",
    "    param.requires_grad = True  # Сохраняем отслеживание градиентов\n",
    "    param.data = new_param  \n",
    "\n",
    "# Прпоускаем градиенты от лосса до весов модели leaf_model и до learning_rate\n",
    "outputs = model_1(images)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "\n",
    "print(learning_rate.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010, device='mps:0', requires_grad=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [MPSFloatType [10]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model_1(images)\n\u001b[1;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/hippotrainer/.venv/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/hippotrainer/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/hippotrainer/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [MPSFloatType [10]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "tensor([[[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]]], device='mps:0') False\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True], device='mps:0') False\n",
      "tensor([[[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]]], device='mps:0') False\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True], device='mps:0') False\n",
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]], device='mps:0') False\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True], device='mps:0') False\n",
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]], device='mps:0') False\n",
      "tensor([True, True, True, True, True, True, True, True, True, True],\n",
      "       device='mps:0') False\n"
     ]
    }
   ],
   "source": [
    "for (name, param), (_, new_param) in zip(model_1.named_parameters(), new_params.items()):\n",
    "    param.requires_grad = False\n",
    "    param.copy_(new_param)\n",
    "    print(param.is_leaf)\n",
    "\n",
    "for (name, param), (_, new_param) in zip(model_1.named_parameters(), new_params.items()):\n",
    "    print((param == new_param), param.is_leaf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n",
      "True False\n",
      "True False\n",
      "True False\n",
      "True False\n",
      "True False\n",
      "True False\n",
      "True False\n"
     ]
    }
   ],
   "source": [
    "for (name, param), (_, new_param) in zip(model_1.named_parameters(), new_params.items()):\n",
    "    # print(param == new_param)\n",
    "    print(param.is_leaf , new_param.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight True\n",
      "True True False\n",
      "tensor([[[[ 3.9311e-07,  6.5936e-07,  1.9188e-07],\n",
      "          [ 1.9255e-07, -5.9283e-07, -5.3736e-07],\n",
      "          [-5.4589e-07, -1.1215e-08, -5.9124e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.0781e-07,  1.9696e-07,  3.6641e-07],\n",
      "          [-2.6646e-07, -6.4334e-07,  2.6286e-07],\n",
      "          [-6.1491e-07,  4.5499e-07,  5.3554e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.4482e-07, -3.0979e-07,  5.9717e-07],\n",
      "          [ 6.3735e-07, -6.5756e-08,  7.2743e-08],\n",
      "          [ 4.5395e-08,  1.7619e-07,  3.6919e-07]]],\n",
      "\n",
      "\n",
      "        [[[-9.7291e-08,  5.0710e-08, -7.9009e-08],\n",
      "          [-3.6320e-08,  5.1337e-07,  7.2386e-08],\n",
      "          [-4.2262e-07, -1.9121e-07,  2.0234e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7434e-07,  2.7896e-08, -4.5730e-07],\n",
      "          [ 6.5972e-07, -3.8540e-07,  2.4600e-07],\n",
      "          [ 6.3775e-07, -2.8126e-07, -1.9622e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6632e-07, -2.0528e-08,  2.3713e-07],\n",
      "          [-4.1091e-07,  6.5803e-07,  3.8207e-07],\n",
      "          [-5.1451e-07, -3.6457e-07, -2.1865e-08]]],\n",
      "\n",
      "\n",
      "        [[[-1.3948e-07, -1.7045e-07,  2.4070e-07],\n",
      "          [ 1.0961e-07, -6.0574e-07,  4.9672e-07],\n",
      "          [-1.3545e-07,  2.0705e-07,  6.4541e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6060e-07,  9.6047e-08, -3.8238e-07],\n",
      "          [ 3.0299e-07, -5.4329e-07, -2.5694e-07],\n",
      "          [ 4.8825e-07,  3.8506e-07,  1.5138e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.9667e-07, -8.5444e-08,  1.7191e-07],\n",
      "          [ 3.9256e-07,  3.6025e-07,  5.4665e-07],\n",
      "          [ 2.8908e-07,  4.4333e-07, -4.6946e-07]]],\n",
      "\n",
      "\n",
      "        [[[-6.5274e-07,  2.4942e-07,  1.1640e-07],\n",
      "          [-1.9626e-07, -3.4497e-07,  1.2086e-07],\n",
      "          [ 2.5333e-07,  6.2006e-08, -1.0046e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0462e-07,  3.0949e-07,  3.2943e-07],\n",
      "          [ 4.7494e-07,  6.0381e-07, -3.9915e-07],\n",
      "          [-1.8992e-07, -2.5134e-07, -2.6386e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.0215e-08, -3.7989e-07, -2.4998e-07],\n",
      "          [ 3.5406e-07,  2.1288e-07,  4.8763e-07],\n",
      "          [-6.2878e-07, -4.3753e-07,  4.4436e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.9565e-07, -5.0347e-08, -2.0893e-08],\n",
      "          [-7.2487e-08,  6.5857e-07, -5.0770e-07],\n",
      "          [-3.6390e-07,  6.3062e-07,  6.7280e-08]]],\n",
      "\n",
      "\n",
      "        [[[-1.4890e-07,  4.3741e-08,  1.5455e-07],\n",
      "          [ 4.6606e-07, -2.5693e-07,  1.0323e-07],\n",
      "          [-6.5846e-07,  5.4768e-07, -3.6484e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.9507e-08, -4.3109e-07, -3.8784e-07],\n",
      "          [-1.8771e-07, -3.9364e-07,  4.4926e-07],\n",
      "          [ 3.7548e-07,  1.6548e-07,  3.2884e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2843e-07, -3.3815e-07,  8.5743e-08],\n",
      "          [-5.8798e-07,  2.1583e-07,  5.3965e-07],\n",
      "          [ 2.1717e-07, -3.2651e-07,  4.4423e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.1949e-07, -3.0053e-07,  2.8322e-08],\n",
      "          [ 6.3577e-07,  7.9565e-08,  1.1881e-07],\n",
      "          [ 5.3951e-07, -2.7752e-07,  5.5138e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.2412e-08, -2.6204e-08,  2.4324e-07],\n",
      "          [ 3.0464e-08, -1.7546e-08, -1.0365e-07],\n",
      "          [-3.8776e-07, -3.8544e-07,  4.2454e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.5920e-07,  4.4550e-07,  1.5465e-07],\n",
      "          [ 5.7223e-07,  5.1307e-07,  1.8987e-07],\n",
      "          [-3.8908e-07, -4.3053e-07,  3.5897e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1703e-07, -4.7987e-07,  3.8120e-07],\n",
      "          [-4.3870e-07,  5.6821e-07, -5.2249e-07],\n",
      "          [ 4.6814e-07,  8.5850e-08, -4.9164e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.9348e-07,  2.6925e-07,  5.2394e-07],\n",
      "          [-5.9901e-07,  4.1281e-07,  4.6223e-08],\n",
      "          [-6.9791e-08,  3.9364e-07,  1.8399e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.6333e-07,  4.3301e-07,  8.5294e-08],\n",
      "          [-4.3515e-07,  1.2693e-07, -8.7630e-08],\n",
      "          [-2.2717e-07,  1.6930e-07, -2.4654e-07]]],\n",
      "\n",
      "\n",
      "        [[[-6.5301e-07, -2.8236e-07, -4.3831e-07],\n",
      "          [-2.1906e-07,  3.7589e-07, -4.5265e-07],\n",
      "          [ 4.2609e-08, -1.4812e-07, -6.5126e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8029e-07,  2.7134e-07,  5.3772e-07],\n",
      "          [ 1.2416e-07,  3.1212e-07, -1.9618e-07],\n",
      "          [ 1.7700e-07, -4.9822e-07, -7.8838e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8312e-07, -3.9091e-07,  1.0251e-07],\n",
      "          [-1.4658e-07, -2.8425e-07,  7.2769e-09],\n",
      "          [ 2.5945e-07,  1.8093e-07, -7.3695e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1087e-07, -8.4798e-08, -5.8764e-07],\n",
      "          [-4.8132e-07, -1.5799e-07,  4.0753e-07],\n",
      "          [ 1.7714e-07, -6.1948e-07,  6.3874e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1670e-08, -2.6981e-07, -5.3287e-07],\n",
      "          [-2.2223e-07,  4.4926e-07,  3.4554e-07],\n",
      "          [-5.0087e-07, -1.6599e-07,  3.1329e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6221e-07, -3.0739e-07,  6.2692e-07],\n",
      "          [ 4.6659e-07,  4.2408e-07,  4.4109e-07],\n",
      "          [-4.7924e-07,  5.9913e-08, -5.9569e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.5217e-07,  2.1708e-07, -6.2538e-07],\n",
      "          [-3.0238e-08, -4.4447e-07, -4.0895e-07],\n",
      "          [ 4.2193e-08,  5.6346e-07,  3.7042e-07]]],\n",
      "\n",
      "\n",
      "        [[[-5.5888e-08, -1.4605e-07,  3.2794e-08],\n",
      "          [-2.5240e-08, -4.7971e-07,  1.8679e-07],\n",
      "          [ 4.2177e-07, -3.2838e-07,  4.9165e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7968e-07, -3.1335e-08, -5.7436e-07],\n",
      "          [ 5.8160e-07, -3.6147e-07,  5.0001e-07],\n",
      "          [ 4.2743e-08, -6.0505e-07,  5.0201e-07]]],\n",
      "\n",
      "\n",
      "        [[[-2.7925e-07, -2.5701e-07,  3.9573e-08],\n",
      "          [-4.6255e-07,  4.9319e-07, -4.5710e-07],\n",
      "          [ 3.8532e-07, -6.4735e-07,  2.3365e-07]]]], device='mps:0')\n",
      "conv1.bias True\n",
      "True True False\n",
      "tensor([-4.6364e-07, -5.6272e-07,  6.1116e-07, -3.4585e-07, -1.7456e-07,\n",
      "        -2.9787e-08,  8.2848e-08, -1.7006e-07, -8.8122e-08, -5.1625e-07,\n",
      "         3.1122e-07,  1.4764e-07,  5.7209e-07, -3.4495e-07, -4.6730e-07,\n",
      "        -4.8004e-07, -3.2169e-07,  6.5707e-07, -2.9590e-07, -6.4464e-07,\n",
      "         5.2237e-07, -1.4021e-07, -1.6696e-07, -4.7598e-07, -6.0792e-07,\n",
      "        -1.1658e-07, -2.7893e-07, -5.2072e-07, -5.3191e-07, -5.1886e-08,\n",
      "        -5.9014e-07, -4.9979e-07], device='mps:0')\n",
      "conv2.weight True\n",
      "True True False\n",
      "tensor([[[[-2.6804e-08, -2.8422e-08, -1.1670e-07],\n",
      "          [ 7.4811e-08,  8.7688e-08, -3.2886e-08],\n",
      "          [-2.6989e-08, -2.7887e-08, -7.2119e-08]],\n",
      "\n",
      "         [[-9.7440e-08, -3.5501e-08, -8.4398e-09],\n",
      "          [ 6.7080e-08,  8.2670e-08,  5.9368e-08],\n",
      "          [-3.0614e-08, -4.4504e-08, -7.9627e-08]],\n",
      "\n",
      "         [[ 2.6072e-08, -8.8538e-08, -4.0019e-08],\n",
      "          [ 6.7526e-08, -3.6538e-08,  4.2334e-08],\n",
      "          [ 8.8440e-08, -9.4007e-08,  5.7713e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8093e-08,  4.5910e-08, -1.1541e-08],\n",
      "          [-4.8325e-08,  2.6100e-08, -4.0475e-08],\n",
      "          [-3.1211e-08, -3.2594e-08,  1.1482e-07]],\n",
      "\n",
      "         [[-7.5739e-08,  5.2647e-08,  1.0738e-07],\n",
      "          [ 1.0632e-07, -2.9877e-08, -1.8717e-08],\n",
      "          [ 5.4840e-08, -7.0072e-08, -1.6249e-08]],\n",
      "\n",
      "         [[-1.0700e-07,  6.2555e-08, -1.1137e-07],\n",
      "          [ 1.5645e-08, -7.4737e-08, -6.7315e-08],\n",
      "          [-1.1370e-07, -1.1118e-08, -6.2583e-09]]],\n",
      "\n",
      "\n",
      "        [[[-8.5004e-09, -5.9082e-08,  6.0634e-09],\n",
      "          [-2.8951e-08, -4.9269e-08, -3.2764e-08],\n",
      "          [-2.0254e-08, -9.6612e-08, -8.0238e-08]],\n",
      "\n",
      "         [[ 3.6067e-08,  3.3741e-08,  2.8044e-08],\n",
      "          [ 4.5344e-08,  6.3837e-08, -1.8875e-08],\n",
      "          [-8.1825e-08, -3.7593e-08, -5.3760e-08]],\n",
      "\n",
      "         [[ 5.6653e-08, -8.1221e-08,  3.2373e-09],\n",
      "          [ 3.9047e-08, -1.7263e-08, -5.2687e-08],\n",
      "          [-4.2518e-08, -9.9970e-08,  3.6266e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6400e-08, -1.0243e-07, -1.1504e-07],\n",
      "          [ 7.8157e-08,  1.0941e-07, -6.1544e-09],\n",
      "          [-3.6540e-08, -5.2561e-08,  1.2443e-08]],\n",
      "\n",
      "         [[-1.1270e-07,  9.8562e-08,  9.3945e-08],\n",
      "          [-8.0447e-08,  1.0846e-07,  3.8480e-08],\n",
      "          [ 6.4266e-09, -6.3917e-08,  9.9029e-08]],\n",
      "\n",
      "         [[-5.0216e-08, -1.0795e-07,  9.5902e-08],\n",
      "          [-1.1767e-07,  9.6503e-08,  5.6929e-08],\n",
      "          [-4.6383e-08, -9.6971e-08, -2.3358e-08]]],\n",
      "\n",
      "\n",
      "        [[[-2.4291e-08, -9.9702e-08,  7.5258e-08],\n",
      "          [-4.6996e-08, -8.2916e-10,  4.6693e-08],\n",
      "          [ 7.0877e-08, -4.2007e-08, -7.0784e-08]],\n",
      "\n",
      "         [[-2.7637e-09, -2.5858e-08, -1.3900e-08],\n",
      "          [ 8.8363e-08,  6.4399e-09,  8.6085e-08],\n",
      "          [-1.0786e-08, -6.1497e-09, -6.1193e-08]],\n",
      "\n",
      "         [[-7.2857e-08, -2.0540e-08, -4.1737e-08],\n",
      "          [-8.4775e-08, -2.1970e-08, -1.0560e-07],\n",
      "          [-6.2784e-08, -6.2042e-08,  7.0062e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.6210e-08, -1.6445e-08, -1.0805e-07],\n",
      "          [ 1.0626e-07,  1.0921e-07,  3.6356e-08],\n",
      "          [ 3.3150e-09,  7.6618e-08,  1.0358e-07]],\n",
      "\n",
      "         [[-1.0929e-07, -7.7361e-08, -4.4691e-08],\n",
      "          [-7.8909e-08, -6.5687e-08,  8.8112e-08],\n",
      "          [ 8.1392e-08,  4.2402e-08,  1.0365e-07]],\n",
      "\n",
      "         [[-4.0497e-08,  9.7605e-08, -5.8739e-08],\n",
      "          [ 6.5939e-08, -1.0081e-07, -3.0243e-08],\n",
      "          [-7.8715e-08, -1.1477e-08, -1.0883e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.3421e-08,  1.0657e-07,  6.0124e-08],\n",
      "          [ 6.1881e-08, -7.0656e-08, -1.0914e-08],\n",
      "          [-2.0461e-08,  3.0936e-08,  7.6996e-08]],\n",
      "\n",
      "         [[-5.9259e-08, -1.1179e-07,  9.3801e-08],\n",
      "          [ 6.3718e-08,  3.5168e-08, -9.0795e-09],\n",
      "          [-1.9843e-08, -7.3384e-08, -1.1639e-07]],\n",
      "\n",
      "         [[-1.0723e-07, -9.0156e-08,  2.3460e-08],\n",
      "          [-5.5492e-09, -2.8171e-08, -6.8244e-08],\n",
      "          [-3.5027e-08, -3.1020e-08,  5.4884e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9388e-08, -3.0002e-08, -2.3940e-08],\n",
      "          [ 3.7844e-08, -7.2567e-09, -9.9591e-08],\n",
      "          [ 6.1741e-08,  3.0927e-08, -8.2974e-08]],\n",
      "\n",
      "         [[-3.9771e-08,  1.1448e-07,  3.0368e-08],\n",
      "          [-2.4860e-08,  4.2037e-08, -7.2672e-08],\n",
      "          [ 9.8885e-09,  7.3627e-08, -1.1123e-07]],\n",
      "\n",
      "         [[ 9.6346e-08,  8.9915e-08, -9.8674e-08],\n",
      "          [-1.1231e-07, -6.4945e-08,  2.8089e-08],\n",
      "          [ 7.7047e-08,  1.1696e-07, -7.2275e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0828e-07,  1.1287e-07, -7.4117e-08],\n",
      "          [-2.6663e-08, -6.1336e-08,  2.7689e-08],\n",
      "          [-2.2471e-08,  2.1082e-08, -9.4334e-09]],\n",
      "\n",
      "         [[ 9.7087e-08, -1.6424e-08, -1.9512e-08],\n",
      "          [ 5.3688e-09, -7.2865e-08, -5.9264e-08],\n",
      "          [ 4.4100e-08,  9.2272e-08, -4.7846e-08]],\n",
      "\n",
      "         [[-4.2867e-08,  6.9610e-08,  9.9472e-08],\n",
      "          [-9.0604e-08,  3.0791e-08,  6.3730e-08],\n",
      "          [-4.2043e-08, -4.1760e-08, -7.4626e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0026e-08, -3.2090e-08,  5.5079e-08],\n",
      "          [-9.9125e-08, -1.1326e-07, -2.1469e-08],\n",
      "          [-8.0770e-08, -9.6857e-08, -3.9835e-08]],\n",
      "\n",
      "         [[ 8.3952e-08,  4.1818e-08,  1.1090e-07],\n",
      "          [ 7.4219e-08,  8.5862e-08,  5.6916e-09],\n",
      "          [ 3.5454e-08,  1.2647e-08,  1.0471e-07]],\n",
      "\n",
      "         [[ 5.0001e-08,  6.1186e-08, -6.8588e-08],\n",
      "          [-1.0440e-08, -4.1791e-08, -5.7820e-08],\n",
      "          [ 1.1696e-07,  7.7411e-08,  4.4978e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5996e-08, -7.3158e-08, -7.5505e-08],\n",
      "          [ 3.2011e-08, -5.2103e-08, -4.6536e-08],\n",
      "          [-8.9806e-08,  9.9937e-08,  2.8334e-08]],\n",
      "\n",
      "         [[ 1.1744e-08,  8.4622e-08, -4.1539e-08],\n",
      "          [-3.8736e-09, -4.0520e-08, -1.1170e-07],\n",
      "          [ 1.0475e-07,  5.4786e-08, -5.2262e-08]],\n",
      "\n",
      "         [[-6.9931e-08, -3.8104e-08,  9.9587e-09],\n",
      "          [ 7.4072e-08, -1.1411e-07, -1.0083e-07],\n",
      "          [-2.0638e-08, -9.6631e-08,  1.1570e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5756e-08,  9.8577e-10,  2.4351e-09],\n",
      "          [ 7.1763e-08,  5.8712e-08,  1.1973e-08],\n",
      "          [ 9.4014e-08, -1.0855e-07,  6.0751e-08]],\n",
      "\n",
      "         [[ 8.6246e-08, -9.3742e-08,  7.2625e-08],\n",
      "          [-9.6335e-08,  2.0422e-09, -3.9023e-08],\n",
      "          [-1.0736e-07,  1.1656e-07, -7.3439e-08]],\n",
      "\n",
      "         [[-9.0316e-08,  4.7847e-08, -7.2818e-08],\n",
      "          [-3.1839e-08,  1.3860e-08,  2.5809e-08],\n",
      "          [-1.0173e-07,  1.4628e-08, -2.9631e-08]]]], device='mps:0')\n",
      "conv2.bias True\n",
      "True True False\n",
      "tensor([ 1.2760e-08,  6.1560e-08,  2.6523e-08,  1.0155e-07,  2.5020e-08,\n",
      "        -8.3652e-08, -4.9993e-08, -3.7435e-08,  4.0494e-08, -1.0787e-08,\n",
      "         7.3407e-08, -2.5065e-08, -5.8703e-08,  7.3727e-08, -1.0569e-07,\n",
      "        -3.7164e-08,  1.1219e-07,  1.0728e-07, -9.8635e-09,  9.0947e-09,\n",
      "        -7.8600e-08, -3.9856e-08, -1.9896e-08,  9.4929e-08, -5.5032e-08,\n",
      "         1.0698e-07,  5.1395e-09, -9.4858e-08, -7.2483e-08, -1.6772e-08,\n",
      "        -8.4576e-08, -6.1227e-09,  5.4005e-08,  7.3202e-10,  9.7425e-08,\n",
      "         2.6578e-09,  2.6561e-09, -3.8775e-08, -1.9475e-08, -3.4200e-08,\n",
      "         4.2562e-08,  8.7720e-08, -1.0543e-07, -1.3695e-08, -6.6475e-08,\n",
      "        -9.8886e-08,  9.3904e-08, -6.1720e-08,  6.8243e-08, -1.1771e-07,\n",
      "         6.1759e-08, -5.7486e-08, -3.4318e-08,  6.6207e-08,  9.6591e-08,\n",
      "        -8.4033e-08, -7.5140e-08, -3.9388e-09,  7.0038e-08, -6.2802e-08,\n",
      "        -3.0590e-10,  9.6391e-08,  4.2614e-08,  8.6688e-08], device='mps:0')\n",
      "fc1.weight True\n",
      "True True False\n",
      "tensor([[-2.3564e-08,  1.5132e-08, -3.6164e-09,  ...,  2.4723e-08,\n",
      "         -1.6470e-08, -2.0784e-08],\n",
      "        [-9.3842e-09, -2.7163e-08, -2.7995e-08,  ...,  2.2936e-08,\n",
      "          1.4663e-08,  8.7053e-09],\n",
      "        [-2.9209e-08, -3.9273e-09, -1.4881e-08,  ...,  3.2440e-08,\n",
      "          2.2767e-08, -2.3768e-08],\n",
      "        ...,\n",
      "        [-2.3250e-08,  3.4704e-08, -1.4406e-08,  ...,  1.6975e-09,\n",
      "          3.5075e-08,  2.1257e-08],\n",
      "        [ 3.3593e-09, -2.9752e-08,  2.9105e-08,  ...,  9.1258e-09,\n",
      "          4.5334e-09,  9.9851e-09],\n",
      "        [-1.7806e-08,  1.9415e-08, -1.2691e-08,  ...,  1.9817e-08,\n",
      "          7.0406e-09,  1.0359e-08]], device='mps:0')\n",
      "fc1.bias True\n",
      "True True False\n",
      "tensor([-1.3525e-08,  8.8434e-09,  1.3255e-08,  5.1047e-09,  2.7785e-08,\n",
      "         3.5706e-08,  2.5823e-08, -1.6801e-08, -4.0667e-11,  2.6366e-08,\n",
      "        -1.8055e-08, -1.8154e-09, -2.1597e-08, -9.2126e-09,  3.2320e-08,\n",
      "        -2.3353e-08, -2.7998e-08,  1.7274e-08,  2.6102e-08, -1.9973e-08,\n",
      "        -1.6348e-08, -7.5533e-09, -2.3277e-08,  1.5481e-08, -1.7208e-08,\n",
      "        -7.2973e-09, -5.4514e-09, -2.9633e-09, -3.4386e-09, -2.7666e-08,\n",
      "         1.0530e-08,  7.5585e-09,  8.8052e-10,  2.4854e-08,  2.2909e-08,\n",
      "         5.3679e-09, -3.2273e-08,  1.8435e-09, -1.8728e-08, -2.9772e-09,\n",
      "         3.4544e-08,  1.8286e-08, -2.8676e-08,  1.3516e-08,  1.6453e-08,\n",
      "         2.9073e-08, -3.3708e-09, -2.1145e-08, -1.9612e-08, -3.0737e-08,\n",
      "        -3.5196e-08, -3.2809e-08,  1.4827e-08, -5.8079e-09, -7.0970e-09,\n",
      "         1.6635e-08, -1.2781e-09,  2.2345e-08,  2.8640e-10, -2.8365e-08,\n",
      "         2.6530e-08, -5.3574e-09,  1.4732e-08, -3.4898e-08, -1.8072e-08,\n",
      "        -1.7351e-08, -2.3271e-08,  2.9191e-08, -4.6044e-09, -1.5687e-08,\n",
      "        -3.2311e-08, -5.4083e-09,  2.4890e-08, -2.5963e-08, -6.1179e-09,\n",
      "         1.2614e-10, -2.5513e-08,  1.0811e-08, -1.7067e-08, -2.0551e-08,\n",
      "        -4.3495e-09, -2.1982e-08,  2.5573e-08,  1.0060e-08,  8.4874e-09,\n",
      "        -1.8759e-08,  1.1683e-08, -2.6997e-08, -1.6970e-08, -1.8833e-08,\n",
      "         4.0168e-09, -3.4297e-08, -4.5871e-09, -1.2368e-08, -2.5265e-08,\n",
      "         3.5155e-08,  3.4812e-08,  9.1617e-09,  2.8196e-09, -6.1309e-09,\n",
      "        -8.0180e-09, -5.9412e-09, -3.2174e-08,  9.0999e-09, -3.0250e-08,\n",
      "        -8.8269e-09, -2.7265e-08,  2.0256e-08,  2.3282e-08, -2.9762e-08,\n",
      "         1.4500e-08,  1.1270e-08,  3.7975e-09,  1.2664e-08,  7.2474e-09,\n",
      "         1.0592e-08,  3.3552e-08,  1.5103e-08, -2.0394e-08,  1.8196e-08,\n",
      "        -1.5985e-08, -1.4189e-08,  3.7611e-09, -2.2651e-08, -2.4034e-08,\n",
      "         2.7029e-08,  1.2587e-08, -1.1683e-08], device='mps:0')\n",
      "fc2.weight True\n",
      "True True False\n",
      "tensor([[ 2.3999e-08, -8.5338e-08, -7.7212e-08,  ...,  1.1485e-07,\n",
      "         -5.4260e-08,  1.2520e-07],\n",
      "        [ 3.2152e-08,  1.6426e-07, -1.3041e-07,  ...,  8.4056e-08,\n",
      "         -1.0859e-07,  9.6029e-08],\n",
      "        [-1.2133e-07,  1.6425e-07,  5.9611e-08,  ..., -1.7355e-07,\n",
      "          9.1369e-08,  1.5639e-07],\n",
      "        ...,\n",
      "        [ 1.3685e-07,  5.9944e-08,  6.3316e-08,  ...,  8.9448e-08,\n",
      "         -5.9923e-08, -5.6123e-08],\n",
      "        [-6.2618e-08, -1.7257e-07, -1.2799e-07,  ...,  6.8664e-10,\n",
      "         -8.5189e-08,  1.5951e-07],\n",
      "        [-1.1191e-07,  8.8201e-08,  1.5211e-07,  ..., -7.6410e-08,\n",
      "         -2.5083e-08,  8.6553e-08]], device='mps:0')\n",
      "fc2.bias True\n",
      "True True False\n",
      "tensor([ 1.3750e-07,  1.5974e-07,  7.5671e-08,  9.9458e-08, -7.2762e-08,\n",
      "        -6.2555e-08,  1.3434e-07,  6.3590e-08, -1.4069e-08, -1.6974e-07],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in leaf_model.named_parameters():\n",
    "    param.grad.zero_()\n",
    "    \n",
    "    print(name , param.grad is not None)\n",
    "    new_param = param * learning_rate\n",
    "    print(param.is_leaf , learning_rate.is_leaf, new_param.is_leaf)\n",
    "\n",
    "    value = torch.sum(new_param**2)\n",
    "    value.backward()\n",
    "\n",
    "    print(param.grad )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_1(images)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9463, device='mps:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
